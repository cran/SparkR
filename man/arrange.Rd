% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generics.R, R/DataFrame.R
\docType{methods}
\name{arrange}
\alias{arrange}
\alias{arrange,SparkDataFrame,Column-method}
\alias{arrange,SparkDataFrame,character-method}
\alias{orderBy,SparkDataFrame,characterOrColumn-method}
\title{Arrange Rows by Variables}
\usage{
arrange(x, col, ...)

\S4method{arrange}{SparkDataFrame,Column}(x, col, ...,
  withinPartitions = FALSE)

\S4method{arrange}{SparkDataFrame,character}(x, col, ...,
  decreasing = FALSE, withinPartitions = FALSE)

\S4method{orderBy}{SparkDataFrame,characterOrColumn}(x, col, ...)
}
\arguments{
\item{x}{a SparkDataFrame to be sorted.}

\item{col}{a character or Column object indicating the fields to sort on}

\item{...}{additional sorting fields}

\item{withinPartitions}{a logical argument indicating whether to sort only within each partition}

\item{decreasing}{a logical argument indicating sorting order for columns when
a character vector is specified for col}
}
\value{
A SparkDataFrame where all elements are sorted.
}
\description{
Sort a SparkDataFrame by the specified column(s).
}
\note{
arrange(SparkDataFrame, Column) since 1.4.0

arrange(SparkDataFrame, character) since 1.4.0

orderBy(SparkDataFrame, characterOrColumn) since 1.4.0
}
\examples{
\dontrun{
sparkR.session()
path <- "path/to/file.json"
df <- read.json(path)
arrange(df, df$col1)
arrange(df, asc(df$col1), desc(abs(df$col2)))
arrange(df, "col1", decreasing = TRUE)
arrange(df, "col1", "col2", decreasing = c(TRUE, FALSE))
arrange(df, "col1", "col2", withinPartitions = TRUE)
}
}
\seealso{
Other SparkDataFrame functions: \code{\link{SparkDataFrame-class}},
  \code{\link{agg}}, \code{\link{alias}},
  \code{\link{as.data.frame}},
  \code{\link{attach,SparkDataFrame-method}},
  \code{\link{broadcast}}, \code{\link{cache}},
  \code{\link{checkpoint}}, \code{\link{coalesce}},
  \code{\link{collect}}, \code{\link{colnames}},
  \code{\link{coltypes}},
  \code{\link{createOrReplaceTempView}},
  \code{\link{crossJoin}}, \code{\link{cube}},
  \code{\link{dapplyCollect}}, \code{\link{dapply}},
  \code{\link{describe}}, \code{\link{dim}},
  \code{\link{distinct}}, \code{\link{dropDuplicates}},
  \code{\link{dropna}}, \code{\link{drop}},
  \code{\link{dtypes}}, \code{\link{exceptAll}},
  \code{\link{except}}, \code{\link{explain}},
  \code{\link{filter}}, \code{\link{first}},
  \code{\link{gapplyCollect}}, \code{\link{gapply}},
  \code{\link{getNumPartitions}}, \code{\link{group_by}},
  \code{\link{head}}, \code{\link{hint}},
  \code{\link{histogram}}, \code{\link{insertInto}},
  \code{\link{intersectAll}}, \code{\link{intersect}},
  \code{\link{isLocal}}, \code{\link{isStreaming}},
  \code{\link{join}}, \code{\link{limit}},
  \code{\link{localCheckpoint}}, \code{\link{merge}},
  \code{\link{mutate}}, \code{\link{ncol}},
  \code{\link{nrow}}, \code{\link{persist}},
  \code{\link{printSchema}}, \code{\link{randomSplit}},
  \code{\link{rbind}}, \code{\link{rename}},
  \code{\link{repartitionByRange}},
  \code{\link{repartition}}, \code{\link{rollup}},
  \code{\link{sample}}, \code{\link{saveAsTable}},
  \code{\link{schema}}, \code{\link{selectExpr}},
  \code{\link{select}}, \code{\link{showDF}},
  \code{\link{show}}, \code{\link{storageLevel}},
  \code{\link{str}}, \code{\link{subset}},
  \code{\link{summary}}, \code{\link{take}},
  \code{\link{toJSON}}, \code{\link{unionByName}},
  \code{\link{union}}, \code{\link{unpersist}},
  \code{\link{withColumn}}, \code{\link{withWatermark}},
  \code{\link{with}}, \code{\link{write.df}},
  \code{\link{write.jdbc}}, \code{\link{write.json}},
  \code{\link{write.orc}}, \code{\link{write.parquet}},
  \code{\link{write.stream}}, \code{\link{write.text}}
}
\concept{SparkDataFrame functions}
